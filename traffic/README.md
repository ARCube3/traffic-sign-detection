Initially I had used the setup which was used in the source code and I found that
it was performing very poorly resulting in high values of loss and accuracy of about
0.05. I assumed that this was because performing convolution and pooling once mainly results in finding boundaries and so I increased the convolution and pooling frequency to 2 with the rest of the settings remaining same and I obtained a very high accuracy of about 0.90-0.95 for training as well as testing data consistently. I increased the convolution and pooling again by one and found no significant increase and so I did not make that change in furthur steps. I then decreased the dropout value from 0.5 to 0.4 and it resulted in increase of accuracy of test set above 0.95. I decreased it furthur to 0.3 
but that increased the train accuracy without decreasing test accuracy sometimes and so to prevent any overfitting I did not make that change.

When I increased the number of hidden layers to 2 and decreased the number of nodes in each hidden layer I found that the model sometimes overfitted and resulted in test accuracy less than 0.90 and so I did not apply this in the final problem. I then changed the number of filters in the convolution layer and found that 32 was the best value for both after some tests. On changing the shape of pool and convolution kernels I found that there was very high underfitting since we would end up reducing the size of the image too small to gain any information.
